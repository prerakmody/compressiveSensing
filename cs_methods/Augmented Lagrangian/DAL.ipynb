{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dual Augmented Lagrangian\n",
    "1. [Github](https://github.com/yaoxuexa/CNNCS/tree/master/dal-master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# % dal - dual augmented Lagrangian method for sparse learaning/reconstruction\n",
    "# %\n",
    "# % Overview:\n",
    "# %  Solves the following optimization problem\n",
    "# %   xx = argmin f(x) + lambda*c(x)\n",
    "# %  where f is a user specified (convex, smooth) loss function and c\n",
    "# %  is a measure of sparsity (currently L1 or grouped L1)\n",
    "# %\n",
    "# % Syntax:\n",
    "# %  [ww, uu, status] = dal(prob, ww0, uu0, A, B, lambda, <opt>)\n",
    "# %\n",
    "# % Inputs:\n",
    "# %  prob   : structure that contains the following fields:\n",
    "# %   .obj      : DAL objective function\n",
    "# %   .floss    : structure with three fields (p: primal loss, d: dual loss, args: arguments to the loss functions)\n",
    "# %   .fspec    : function handle to the regularizer spectrum function \n",
    "# %               (absolute values for L1, vector of norms for grouped L1, etc.)\n",
    "# %   .dnorm    : function handle to the conjugate of the regularizer function\n",
    "# %               (max(abs(x)) for L1, max(norms) for grouped L1, etc.)\n",
    "# %   .softth   : soft threshold function\n",
    "# %   .mm       : number of samples (scalar)\n",
    "# %   .nn       : number of unknown variables (scalar)\n",
    "# %   .ll       : lower constraint for the Lagrangian multipliers ([mm,1])\n",
    "# %   .uu       : upper constraint for the Lagrangian multipliers ([mm,1])\n",
    "# %   .Ac       : inequality constraint Ac*aa<=bc for the LMs ([pp,mm])\n",
    "# %   .bc       :                                             ([pp,1])\n",
    "# %   .info     : auxiliary variables for the objective function\n",
    "# %   .stopcond : function handle for the stopping condition\n",
    "# %   .hessMult : function handle to the Hessian product function (H*x)\n",
    "# %   .softth : function handle to the \"soft threshold\" function\n",
    "# %  ww0    : initial solution ([nn,1)\n",
    "# %  uu0    : initial unregularized component ([nu,1])\n",
    "# %  A          : struct with fields times, Ttimes, & slice.\n",
    "# %   .times    : function handle to the function A*x.\n",
    "# %   .Ttimes   : function handle to the function A'*y.\n",
    "# %   .slice    : function handle to the function A(:,I).\n",
    "# %  B      : design matrix for the unregularized component ([mm,nu])\n",
    "# %  lambda : regularization constant (scalar)\n",
    "# %  <opt>  : list of 'fieldname1', value1, 'filedname2', value2, ...\n",
    "# %   aa        : initial Lagrangian multiplier [mm,1] (default zero(mm,1))\n",
    "# %   tol       : tolerance (default 1e-3)\n",
    "# %   maxiter   : maximum number of outer iterations (default 100)\n",
    "# %   eta       : initial barrier parameter (default 1)\n",
    "# %   eps       : initial internal tolerance parameter (default 1e-4)\n",
    "# %   eta_multp : multiplying factor for eta (default 2)\n",
    "# %   eps_multp : multiplying factor for eps (default 0.5)\n",
    "# %   solver    : internal solver. Can be either:\n",
    "# %               'nt'   : Newton method with cholesky factorization\n",
    "# %               'ntsv' : Newton method memory saving (slightly slower)\n",
    "# %               'cg'   : Newton method with PCG (default)\n",
    "# %               'qn'   : Quasi-Newton method\n",
    "# %   display   : display level (0: none, 1: only the last, 2: every\n",
    "# %               outer iteration, (default) 3: every inner iteration)\n",
    "# %   iter      : output the value of ww at each iteration \n",
    "# %               (boolean, default 0)\n",
    "# % Outputs:\n",
    "# %  ww     : the final solution\n",
    "# %  uu     : the final unregularized component\n",
    "# %  status : various status values\n",
    "# %\n",
    "# % Reference:\n",
    "# % \"Super-Linear Convergence of Dual Augmented Lagrangian Algorithm\n",
    "# % for Sparse Learning.\"\n",
    "# % Ryota Tomioka, Taiji Suzuki, and Masashi Sugiyama. JMLR, 2011. \n",
    "# % \"Dual Augmented Lagrangian Method for Efficient Sparse Reconstruction\"\n",
    "# % Ryota Tomioka and Masashi Sugiyama\n",
    "# % http://arxiv.org/abs/0904.0584\n",
    "# % \n",
    "# % Copyright(c) 2009-2011 Ryota Tomioka\n",
    "# % This software is distributed under the MIT license. See license.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     38,
     106
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dalsql1(ww, A, bb, lambdaa):\n",
    "    # opt = propertylist2struct(varargin{:});\n",
    "    # opt = set_defaults(opt,'solver','cg','stopcond','pdg');\n",
    "    prob.floss = struct('p', @loss_sqp, 'd', @loss_sqd, 'args', {{bb}})\n",
    "    prob.fspec = lambda xx : abs(xx)\n",
    "    prob.dnorm = lambda vv : max(abs(vv))\n",
    "    prob.obj = @objdall1\n",
    "    probj.softh = @l1_softh\n",
    "    prob.stopcond = opt.stopcond\n",
    "    prob.ll = -np.inf * np.ones(bb.shape)\n",
    "    prob.uu = np.inf * np.ones(bb.shape)\n",
    "    prob.Ac = []\n",
    "    prob.bc = []\n",
    "    prob.info = []\n",
    "    \n",
    "    if opt.solver == 'cg':\n",
    "        prob.hessMult = @hessMultdall1\n",
    "    \n",
    "    if opt.stopconf = 'fval':\n",
    "        opt.feval = 1\n",
    "    \n",
    "    if isnumeric(A):\n",
    "        A = A[:,:]\n",
    "        mm, nn = A.shape\n",
    "        fA = struct('times', lambda x: A*x, 'Ttimes', lambda x: A.T*x, 'slice', lambda I = A[:,I])\n",
    "    elif iscell(A):\n",
    "        mm = A{3}\n",
    "        nn = A{4}\n",
    "        fAslice = lambda I : fA(sparse)...\n",
    "    else:\n",
    "        print ('A must either be numeric or cell')\n",
    "    \n",
    "    prob.mm = mm\n",
    "    pro.nn = nn\n",
    "    \n",
    "    opt.display = 0\n",
    "    ww, uu, status = dal(prob, ww, [], fA, [], lambdaa, opt)\n",
    "\n",
    "def dal(prob, ww0, uu0, A, B, lambdaa):\n",
    "    opt = {'tol' : 0.001, 'iterr':0, 'maxiter':1000, 'eta':[], 'eps':1, 'eps_multp':-.99, 'eta_multp':2\n",
    "                   'solver': 'cg', 'boostb':1, 'display':2 } \n",
    "    \n",
    "    prob = { 'll' : -np.inf * np.ones((prob.mm, 1)), \n",
    "             'uu' : np.inf * np.ones((prob.mm, 1)),\n",
    "             'Ac' : [],\n",
    "             'bc' : [],\n",
    "             'info' : [],\n",
    "             'finddir' : []\n",
    "           }\n",
    "    if len(opt.eta) == 0:\n",
    "        opt.eta = 0.01/ lambdaa\n",
    "    \n",
    "    if len(uu0) == 0 and len(opt.eta) == 1:\n",
    "        opt.eta = opt.eta * [1, 1]\n",
    "    \n",
    "    if len(uu0) == 0 and len(opt.eta_multp) < 2:\n",
    "        opt.eta_multp = opt.eta_multp * [1,1]\n",
    "    \n",
    "    if opt.display > 0:\n",
    "        if len(uu0) == 0:\n",
    "            nuu = len(uu0)\n",
    "            vstr = str(prob.nn) + ' + ' + str(nuu)\n",
    "        else:\n",
    "            vstr = str(prob.nn)\n",
    "        \n",
    "        lstr = str(prob.floss.p)\n",
    "        lstr = lstr[5:-1]\n",
    "        print ('DAL ver1.05\\n')\n",
    "        print ('#samples = ', prob.mm, ' #variables = ', vstr, ' #lambda = ', lambdaa, ' #loss = ', lstr, ' #solver = ', opt.solver)\n",
    "    \n",
    "    if opt.iterr:\n",
    "        nwu  = len(ww0[:]) + len(uu0[:])\n",
    "        xx = np.hstack(( np.vstack((ww0[:], uu0[:])), np.ones((nwu, opt.maxiter - 1) * np.nan) ))\n",
    "    \n",
    "    res = np.nan * np.ones((1, opt.maxiter))\n",
    "    fval = np.nan * np.ones((1, opt.maxiter))\n",
    "    etaout = np.nan * np.ones((len(opt.eta), opt.maxiter))\n",
    "    time = np.nan * np.ones((1, opt.maxiter))\n",
    "    xi = np.nan * np.ones((1, opt.maxiter))\n",
    "    num_pcg = np.nan * np.ones((1, opt.maxiter))\n",
    "    \n",
    "    time0 = time.time()\n",
    "    ww = ww0\n",
    "    uu = uu0\n",
    "    gtmp = np.zeros(ww.shape)\n",
    "    \n",
    "    if len(opt.aa):\n",
    "        ff, gg = evalloss(prob, ww, uu, A, B)\n",
    "        aa = -gg\n",
    "        if np.any(aa = prob.ll) || np.any(aa == prob.uu):\n",
    "            print ('Invalid initial solution; using instead using ww = np.zeros((n,1))/n')\n",
    "            w0 = np.zeros((prob.nn, 1))\n",
    "            ff, gg = evalloss(prob, w0, uu, A, B)\n",
    "            aa = -gg\n",
    "    \n",
    "    else:\n",
    "        aa = opt.aa\n",
    "    \n",
    "    dval = np.inf\n",
    "    eta = opt.eta\n",
    "    epsl = opt.eps\n",
    "    info = prob.info\n",
    "    info.solver = opt.solver\n",
    "    info.ATaa = []\n",
    "    spec = prob.fspec(ww)\n",
    "    \n",
    "    for ii in range(maxiter):\n",
    "        ww_old = ww\n",
    "        uu_old = uu\n",
    "        etaout[:,ii] = eta.T\n",
    "        time[ii] = time.time() - time0\n",
    "        \n",
    "        # Evaluate objectionve and check stopping condition\n",
    "        fval[ii] = evalprim(prob, ww, uu, A, B, lambdaa)\n",
    "        \n",
    "        if prob.stopcond == 'pdg':\n",
    "            dval = min(dval, evaldual(prob, aa, A, B, lambdaa))\n",
    "            res[ii] = (fval[ii] - (-dval)) / fval[ii]\n",
    "            ret = res[ii] < opt.tol\n",
    "        elif prob.stopcond == 'fval':\n",
    "            res[ii] = fval[ii] - opt.tol\n",
    "            ret = res[ii] <= 0\n",
    "        \n",
    "        if ret != 0:\n",
    "            break\n",
    "        \n",
    "        #Save the original dual variable for daltv2d\n",
    "        fun = lambda aa, info : prob.obj(aa, info, prob, ww, uu, A, B, lamdba, eta)\n",
    "        \n",
    "        if len(opt.eps) > 1:\n",
    "            epsl = opt.eps[ii]\n",
    "        \n",
    "        if opt.solver in ['nt', 'ntsv']:\n",
    "            aa, dfval, dgg, stat = newton(fun, aa, prob.ll, prob.uu, prob.Ac, prob.bc, epsl, prob.finddir, info, opt.display > 2)\n",
    "        elif opt.solver == 'cg':\n",
    "            funh = lambda xx, Hinfo = prob.hessMult(xx, A, eta, Hinfo)\n",
    "            fh = {fun, funh}\n",
    "            aa, dfval, dgg, stat = newton(fh, aa, prob.ll, prob.uu, prob.A, prob.bc, epsl, prob.finddir, info, opt.display > 2)\n",
    "        elif opt.solver == 'qn':\n",
    "            optlbfgs = {'epsginfo':epsl, 'display':opt.display - 1}\n",
    "            aa, stat = lbfgs(fun, aa, prob.ll, prob.uu, prob.Ac, prob.bc, info, optlbfgs)\n",
    "        elif opt.solver == 'fminunc':\n",
    "            optfm = optimset('LargeScale','on','GradObj','on','Hessian'\n",
    "                               , 'on','TolFun',1e-16,'TolX',0,'MaxIter',1000,'display','iter')\n",
    "            aa, fvalin, exitflag = fminunc(lambda x: objdall1fminunc(xx, prob, ww, uu, A, B, lambdaa, eta, epsl)\n",
    "                                               , aa, optfm)\n",
    "            stat.info = info\n",
    "            stat.ret = exitflag != 1\n",
    "            stat.num_pcg = np.nan\n",
    "        else:\n",
    "            print ('Unknown solver', opt.solver)\n",
    "        \n",
    "        info = stat.info\n",
    "        x[ii] = info.ginfo\n",
    "        num_pcg[ii] = stat.num_pcg\n",
    "        \n",
    "        ## Update primal variable\n",
    "        if prob['Aeq']:\n",
    "            I1 = range(0, mm - prob.meq + 1)\n",
    "            I2 = range(mm - prob.meq, mm + 1)\n",
    "            gtmlp[:] = A.Ttimes(aa(I1)) + (prob.Aeq.T * aa(I2))\n",
    "            ww, spec = prob.softth(ww + eta(1)*gtmp, eta(1)*lambda, info)\n",
    "        else:\n",
    "            ww = info.wnew\n",
    "            spec = info.spec\n",
    "        \n",
    "        if len(uu):\n",
    "            if prob.Aeq:\n",
    "                uu = uu + eta(2) * (B.T * aa(range(end - prob.meq +1 )))\n",
    "            else:\n",
    "                uu = uu + eta(2)*(B.T * aa)\n",
    "        \n",
    "        # Boosting the bias term\n",
    "        if len(eta) > 1:\n",
    "            viol = np.hstack(( np.linalg.norm(ww - ww_old)/eta(1), np.linalg.norm(uu - uu_old)/eta(2) ))\n",
    "            if opt.boostb and ii > 1 and viol(2) > viol_old * 0.5 and voil(2) > min(0.001, opt.tol):\n",
    "                eta(2 = eta(2) * 20 ** (stat.ret == 0)\n",
    "            viol_old = viol(2)\n",
    "        \n",
    "        eta = np.mul(eta, opt.eta_multp ** (stat.ret == 0))\n",
    "        epsl = epsl * opt.eps_multp ** (stat.ret == 0)\n",
    "        if opt.iter:\n",
    "            x[:, ii + 1] = np.hstack((ww[:], uu[:]))\n",
    "    \n",
    "    res[ii:] = []\n",
    "    fval[ii:] = []\n",
    "    time[ii:] = []\n",
    "    etaout[:,ii:] = []\n",
    "    xi[ii:] = []\n",
    "    num_pcg[ii:] = []\n",
    "    \n",
    "    if opt.iter:\n",
    "        xx[:, ii+1:] = []\n",
    "    else:\n",
    "        xx = ww\n",
    "    \n",
    "                    \n",
    "    status = {'aa':aa, 'niter':length(res), 'eta':etaout,'xi':xi,'time':time,'res':res,'opt':opt,\n",
    "              'info':info, 'fval':fval, 'num_pcg':num_pcg\n",
    "             }\n",
    "    return xx, uu, status\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "def evalloss(prob, ww, uu, A, B):\n",
    "    fnc = prob.floss\n",
    "    if len(uu):\n",
    "        zz = A.times(WW) + B * uu\n",
    "    else:\n",
    "        zz = A.times(ww)\n",
    "    \n",
    "    fval, gg = fnc.p(zz)\n",
    "                    \n",
    "    return fval, gg\n",
    "\n",
    "## Evaluate the primal objective\n",
    "def evalprim(prob, ww, uu, A, B, lambdaa):\n",
    "    spec = prob.fspec(ww)\n",
    "    fval = evalloss(prob, ww, uu, A, B) + lambdaa * sum(spec)\n",
    "    \n",
    "    if prob.Aeq:\n",
    "        fval += np.linalg.norm(prob.Aeq * ww - prob.ceq)**2/tol\n",
    "    \n",
    "    return fval\n",
    "\n",
    "def evaldual(prob, aa, A, B, lambdaa):\n",
    "    mm = len(aa)\n",
    "    fnc = prob.floss\n",
    "    \n",
    "    if len(B):\n",
    "        aa1 = aa[I1]\n",
    "        aa[I1] = aa1 - B * (B.T * B)/ (B.T * aa1)\n",
    "    else:\n",
    "        aa = aa - B * (B.T * B)/ (B.T * aa1)\n",
    "                    \n",
    "    if prob.Aeq:\n",
    "        I1 = range(mm - prob.meq + 1)\n",
    "        I2 = range(mm-prob.meq, mm + 1)\n",
    "        vv = A.TTimes(aa[I1]) + prob.Aeq.T * aa[I2]\n",
    "    else:\n",
    "        vv = A.Times[aa]\n",
    "                    \n",
    "    dnm, ishard = prob.dnorm(vv)\n",
    "                    \n",
    "    if ishard and dnm > 0:\n",
    "        aa = min(1, lambda.dnm) * aa\n",
    "        dnm = 0\n",
    "    \n",
    "    dval = fnc.d(aa) + dnm\n",
    "                \n",
    "    return dval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
