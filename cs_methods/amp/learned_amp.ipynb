{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T17:31:30.618615Z",
     "start_time": "2017-09-22T17:31:30.533297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_gpu(verbose = 1):\n",
    "    import os\n",
    "\n",
    "    if verbose:\n",
    "        print ('\\n0. Nvidia Hardware (lspci | grep -i nvidia) : ', [each for each in os.popen('lspci | grep -i nvidia')])\n",
    "        print ('0. Nvidia Driver (cat /proc/driver/nvidia/version) : ', [each for each in os.popen('cat /proc/driver/nvidia/version')][0])\n",
    "        print ('0. Nvidia Driver (ls /usr/lib | grep nvidia-) : ', [each for each in os.popen('ls /usr/lib | grep nvidia-')])\n",
    "        print ('0. Nvidia Driver : (dpkg --get-selections | grep nvidia) : ')\n",
    "        for each in os.popen('dpkg --get-selections | grep nvidia'):\n",
    "            print (each)\n",
    "        print ('\\n0. Envs  : CUDA_HOME', os.environ['CUDA_HOME'])\n",
    "        print ('0. Envs  : CUDA_ROOT',os.environ['CUDA_ROOT'])\n",
    "        print ('0. Envs  : LD_LIBRARY_PATH:', os.environ['LD_LIBRARY_PATH'])\n",
    "        print ('0. Envs  : PATH (containing cuda)', [each for each in os.environ['PATH'].split(':') if each.find('cuda') > -1])\n",
    "        print ('0. CUDnn :', [each.replace('\\n', '') for each in os.popen('find /usr/local/cuda-8.0/ -name *dnn*')])\n",
    "\n",
    "    from keras import backend as K\n",
    "    K.clear_session()\n",
    "\n",
    "    print ('\\n0. Keras backend:', K.backend())\n",
    "    if K.backend() == 'tensorflow':\n",
    "        from tensorflow.python.client import device_lib\n",
    "        devices = device_lib.list_local_devices()\n",
    "        for device in devices:\n",
    "            print ('0. TensorFlow Devices:', str(device.name).replace('\\n',''))\n",
    "        print ('\\n')\n",
    "\n",
    "        return 1 if len(devices) > 1 else 0\n",
    "\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORIGINAL SOURCE CODE\n",
    "[Github](https://github.com/mborgerding/onsager_deep_learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T17:33:28.098432Z",
     "start_time": "2017-09-22T17:31:34.892294Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0. Keras backend: tensorflow\n",
      "0. TensorFlow Devices: /cpu:0\n",
      "0. TensorFlow Devices: /gpu:0\n",
      "\n",
      "\n",
      "1. Problem created : bernoulli_gaussian_trial\n",
      "A: (250, 500)\n",
      "X: (500, 1000)  prob.x_: Tensor(\"x:0\", shape=(500, ?), dtype=float32)\n",
      "y: (250, 1000)  prob.y_: Tensor(\"y:0\", shape=(250, ?), dtype=float32)\n",
      "Samples for training: 1000\n",
      "\n",
      "2. Original theta: (1, 2.1972245773362196)\n",
      "2. Eta function returns: xhat Tensor(\"truediv_4:0\", shape=(500, ?), dtype=float32)  dxdr_ Tensor(\"Mean:0\", shape=(?,), dtype=float32)\n",
      "\n",
      "2. Network Built : LAMP with  12  layers\n",
      "0  :  ('Linear', <tf.Tensor 'MatMul_1:0' shape=(500, ?) dtype=float32>, None)\n",
      "1  :  ('LAMP-bg T=1', <tf.Tensor 'truediv_4:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_0:0' shape=(2,) dtype=float32_ref>,))\n",
      "2  :  ('LAMP-bg non-linear T=2', <tf.Tensor 'truediv_10:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_1:0' shape=(2,) dtype=float32_ref>,))\n",
      "3  :  ('LAMP-bg non-linear T=3', <tf.Tensor 'truediv_16:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_2:0' shape=(2,) dtype=float32_ref>,))\n",
      "4  :  ('LAMP-bg non-linear T=4', <tf.Tensor 'truediv_22:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_3:0' shape=(2,) dtype=float32_ref>,))\n",
      "5  :  ('LAMP-bg non-linear T=5', <tf.Tensor 'truediv_28:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_4:0' shape=(2,) dtype=float32_ref>,))\n",
      "6  :  ('LAMP-bg non-linear T=6', <tf.Tensor 'truediv_34:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_5:0' shape=(2,) dtype=float32_ref>,))\n",
      "7  :  ('LAMP-bg non-linear T=7', <tf.Tensor 'truediv_40:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_6:0' shape=(2,) dtype=float32_ref>,))\n",
      "8  :  ('LAMP-bg non-linear T=8', <tf.Tensor 'truediv_46:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_7:0' shape=(2,) dtype=float32_ref>,))\n",
      "9  :  ('LAMP-bg non-linear T=9', <tf.Tensor 'truediv_52:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_8:0' shape=(2,) dtype=float32_ref>,))\n",
      "10  :  ('LAMP-bg non-linear T=10', <tf.Tensor 'truediv_58:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_9:0' shape=(2,) dtype=float32_ref>,))\n",
      "11  :  ('LAMP-bg non-linear T=11', <tf.Tensor 'truediv_64:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_10:0' shape=(2,) dtype=float32_ref>,))\n",
      "12  :  ('LAMP-bg non-linear T=12', <tf.Tensor 'truediv_70:0' shape=(500, ?) dtype=float32>, (<tf.Variable 'theta_11:0' shape=(2,) dtype=float32_ref>,))\n",
      "\n",
      "3. Turning layers into training stages\n",
      "3. maskX_ :  1\n",
      "3, nMSE denominator :  Tensor(\"L2Loss:0\", shape=(), dtype=float32)\n",
      "\n",
      "4.    \n",
      "\n",
      "4. norms xval:224.5513763 yval:224.0477230\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'savefile_load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c2cd2f1b473f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m## do the learning (takes a while)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_stages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LAMP_bg_giid.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/strider/projects/compressiveSensing/cs_methods/amp/learned_amp_train.py\u001b[0m in \u001b[0;36mdo_training\u001b[0;34m(training_stages, prob, savefile, ivl, maxit, better_wait)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n4. norms xval:{xval:.7f} yval:{yval:.7f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msavefile_load\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trainable_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msavefile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# must load AFTER the initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'savefile_load' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if (check_gpu(verbose=0)):\n",
    "        #!/usr/bin/python\n",
    "        \n",
    "        \"\"\"\n",
    "        This file serves as an example of how to \n",
    "        a) select a problem to be solved \n",
    "        b) select a network type\n",
    "        c) train the network to minimize recovery MSE\n",
    "        \"\"\"\n",
    "        import numpy as np\n",
    "        import os\n",
    "\n",
    "        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # BE QUIET!!!!\n",
    "        import tensorflow as tf\n",
    "\n",
    "        np.random.seed(1) # numpy is good about making repeatable output\n",
    "        tf.set_random_seed(1) # on the other hand, this is basically useless (see issue 9171)\n",
    "\n",
    "        # import our problems, networks and training modules\n",
    "        # from tools import problems,networks,train\n",
    "        import learned_amp_problems as problems\n",
    "        import learned_amp_train as train\n",
    "        import learned_amp_networks as networks\n",
    "\n",
    "        # 1. Create the basic problem structure.\n",
    "        prob = problems.bernoulli_gaussian_trial(kappa=None,M=250,N=500,L=1000,pnz=.1,SNR=40) #a Bernoulli-Gaussian x, noisily observed through a random matrix\n",
    "        #prob = problems.random_access_problem(2) # 1 or 2 for compressive random access or massive MIMO\n",
    "        print ('1. Problem created : bernoulli_gaussian_trial')\n",
    "        print ('A:', prob.A.shape)\n",
    "        print ('X:', prob.xval.shape, ' prob.x_:', prob.x_)\n",
    "        print ('y:', prob.yval.shape, ' prob.y_:', prob.y_)\n",
    "        print ('Samples for training:', prob.xval.shape[1])\n",
    "\n",
    "        ## build a LAMP network to solve the problem and get the intermediate results so we can greedily extend and then refine(fine-tune)\n",
    "        T = 12\n",
    "        layers = networks.build_LAMP(prob,T=T,shrink='bg',untied=False)\n",
    "        print ('\\n2. Network Built : LAMP with ', T, ' layers')\n",
    "        for i, layer in enumerate(layers):\n",
    "            print (i, ' : ', layer)\n",
    "\n",
    "        # plan the learning\n",
    "        print ('\\n3. Turning layers into training stages')\n",
    "        training_stages = train.setup_training(layers,prob,trinit=1e-3,refinements=(.5,.1,.01) )\n",
    "\n",
    "        ## do the learning (takes a while)\n",
    "        sess = train.do_training(training_stages,prob,'LAMP_bg_giid.npz', maxit = 30000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-22T10:59:56.471462Z",
     "start_time": "2017-09-22T10:59:56.295847Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
