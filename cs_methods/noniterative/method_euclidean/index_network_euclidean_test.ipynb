{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "1. Recreate the model.\n",
    "2. Add the weights\n",
    "3. Split your image into equivalient parts\n",
    "4. Apply phi on them\n",
    "5. Pass them through the NN\n",
    "6. Reconstruct the image via its parts\n",
    "7. Apply BN3D denoiser\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL PREDICTS LOCAL PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     16,
     27,
     50,
     70
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import utils\n",
    "\n",
    "import io\n",
    "import joblib\n",
    "import image_slicer\n",
    "import numpy as np\n",
    "import scipy.ndimage as spimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "np.random.seed(7)\n",
    "%matplotlib inline\n",
    "\n",
    "def get_data_patches(url_local, file):\n",
    "    obj = spimg.imread(url_local + '/' + file, flatten=True, mode = 'L')\n",
    "    print (obj.shape)\n",
    "    tiles = image_slicer.main.slice(url_local + '/' + file, 4, save=False)\n",
    "    for tile in tiles:\n",
    "        print (tile)\n",
    "        with io.BytesIO() as data:\n",
    "            tile.save(data)\n",
    "            tmp = data.getvalue()\n",
    "            # print (tmp)\n",
    "\n",
    "def get_data_patches_v2(url_datafolder, suburl_phi, suburl_testfolder, suburl_testimage):\n",
    "    objs_original = []\n",
    "    objs_phi = []\n",
    "    \n",
    "    with open(url_datafolder + suburl_phi, 'rb') as handle:\n",
    "        phi = joblib.load(handle)\n",
    "    print ('Phi:', phi, phi.shape)\n",
    "    \n",
    "    obj = spimg.imread(url_datafolder + suburl_testfolder + suburl_testimage, flatten=True, mode = 'L')\n",
    "    plt.imshow(obj, cmap = plt.cm.gray)\n",
    "    print ('Original Image:', obj.shape)\n",
    "    obj_patches = image.extract_patches_2d(obj, (33, 33), max_patches=10)\n",
    "    for obj_patch in obj_patches:\n",
    "        objs_original.append(obj_patch)\n",
    "        obj_patch_flatten = obj_patch.reshape((1, obj_patch.shape[0] * obj_patch.shape[1]))\n",
    "        obj_patch_phi = (obj_patch_flatten * phi).reshape(33,33)\n",
    "        objs_phi.append(obj_patch_phi)\n",
    "        f, axarr = plt.subplots(1,2)\n",
    "        axarr[0].imshow(obj_patch, cmap = plt.cm.gray)\n",
    "        axarr[1].imshow(obj_patch_phi, cmap = plt.cm.gray)\n",
    "    \n",
    "    return objs_original, objs_phi\n",
    "\n",
    "def model_disk(action, filename_model_arch, filename_model_weights, model=''):\n",
    "    from keras.models import model_from_json\n",
    "    \n",
    "    print ('\\n3. --------------------------------------> Model on Disk')\n",
    "    if action == 'save':\n",
    "        with open(filename_model_arch, \"w\") as handle:\n",
    "            handle.write(model.to_json())\n",
    "        model.save_weights(filename_model_weights)\n",
    "        print(\"\\nSaved model to disk\")\n",
    "        \n",
    "    elif action == 'load':\n",
    "        json_file = open(filename_model_arch, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        model.load_weights(filename_model_weights)\n",
    "        print(\"Loaded model from disk\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # get_data_patches('../data/original/SRCNN/Test/Set14/', 'baboon.bmp')\n",
    "    # get_data_patches_v2('../data/','mr_70/data_phi.gz','original/SRCNN/Test/Set14/', 'lenna.bmp')\n",
    "    objs_original, objs_phi = get_data_patches_v2('../data/','mr_70/data_phi.gz'\n",
    "                                                      ,'original/SRCNN/Test/Set14/', 'monarch.bmp')\n",
    "    \n",
    "    model = model_disk('load', 'model/index_network_euclidean_keras_model.json'\n",
    "                               , 'model/index_network_euclidean_keras_weights.h5'\n",
    "                               , ''\n",
    "                       )\n",
    "    for i, obj_phi in enumerate(objs_phi):\n",
    "        obj_predict = model.predict(obj_phi.reshape(1,1,33,33))\n",
    "        print ('obj_predict:', obj_predict.shape)\n",
    "\n",
    "        f, axarr = plt.subplots(1,3)\n",
    "        axarr[0].imshow(obj_phi.reshape(33,33), cmap = plt.cm.gray)\n",
    "        axarr[1].imshow(objs_original[i].reshape(33,33), cmap = plt.cm.gray)\n",
    "        axarr[2].imshow(obj_predict.reshape(33, 33), cmap = plt.cm.gray)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL PREDICTS LOCAL PATCHES AND STITCHES THEM TOGETHER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-05T15:23:44.191754Z",
     "start_time": "2017-10-05T15:23:07.112046Z"
    },
    "code_folding": [
     17
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Phi: [[1 1 0 ..., 0 0 0]] (1, 1089)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. --------------------------------------> Model on Disk\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model_mr20/index_network_euclidean_keras_model.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4f6c8f19c458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m         model = utils.model_disk('load', MODEL_FOLDER + '/index_network_euclidean_keras_model.json'\n\u001b[1;32m     97\u001b[0m                                \u001b[0;34m,\u001b[0m \u001b[0mMODEL_FOLDER\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/index_network_euclidean_keras_weights.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                \u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                        )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/strider/projects/compressiveSensing/cs_methods/noniterative/utils.py\u001b[0m in \u001b[0;36mmodel_disk\u001b[0;34m(action, filename_model_arch, filename_model_weights, model)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'load'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_model_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mloaded_model_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_mr20/index_network_euclidean_keras_model.json'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import joblib\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def crop(Path, input, height, width, phi, model):\n",
    "    im = Image.open(input)\n",
    "    print ('3. Original Image:', im.size, im.mode)\n",
    "    im = im.convert(\"L\")\n",
    "    \n",
    "    im_numpy = np.array(im)\n",
    "    plt.imshow(im_numpy, cmap = plt.cm.gray)\n",
    "    \n",
    "    im_array_orig = []\n",
    "    im_array_phi = []\n",
    "    im_array_pred = []\n",
    "    \n",
    "    im_array_orig_combined = []\n",
    "    im_array_phi_combined = []\n",
    "    im_array_pred_combined = []\n",
    "    \n",
    "    \n",
    "    imgwidth, imgheight = im.size\n",
    "    total_plots = len(range(0, imgheight, height))\n",
    "    # f, axarr_orig = plt.subplots(total_plots-1,1)\n",
    "    # f, axarr_pred = plt.subplots(total_plots-1,1)\n",
    "    \n",
    "    for row, i in enumerate(range(0, imgheight, height)):\n",
    "        # print ('3. Row:', row, '/', total_plots)\n",
    "        if row > 0:\n",
    "            tmp_img_array_orig = np.array(im_array_orig)\n",
    "            # print ('1. Row:',row-1, ' Image:', tmp_img_array.shape)\n",
    "            tmp_img_array_orig = np.concatenate(tmp_img_array_orig, axis = 1)\n",
    "            # axarr_orig[row-1].imshow(tmp_img_array_orig, cmap = plt.cm.gray)\n",
    "            im_array_orig_combined.append(tmp_img_array_orig)\n",
    "\n",
    "            tmp_img_array_phi = np.array(im_array_phi)\n",
    "            tmp_img_array_phi = np.concatenate(tmp_img_array_phi, axis = 1)\n",
    "            im_array_phi_combined.append(tmp_img_array_phi)\n",
    "\n",
    "            tmp_img_array_pred = np.array(im_array_pred)\n",
    "            tmp_img_array_pred = np.concatenate(tmp_img_array_pred, axis = 1)\n",
    "            # axarr_pred[row-1].imshow(tmp_img_array_pred, cmap = plt.cm.gray)\n",
    "            im_array_pred_combined.append(tmp_img_array_pred)\n",
    "\n",
    "        im_array_orig = []\n",
    "        im_array_phi = []\n",
    "        im_array_pred = []\n",
    "\n",
    "        for j in range(0, imgwidth, width):\n",
    "            box = (j, i, j+width, i+height)  #(x1, y1, x2, y2) (0,0) <-- top-left corner\n",
    "            im_cropped_tmp = np.array(im.crop(box))\n",
    "\n",
    "            im_array_orig.append(im_cropped_tmp)\n",
    "            img_phi_tmp = im_cropped_tmp.reshape(1, width * height) * phi\n",
    "            im_array_phi.append(img_phi_tmp.reshape(width, height))\n",
    "            im_array_pred_tmp = model.predict((img_phi_tmp).reshape(1,1, width, height))\n",
    "            im_array_pred.append(im_array_pred_tmp.reshape(width, height))\n",
    "    \n",
    "    im_array_orig_combined = np.concatenate(im_array_orig_combined, axis = 0)\n",
    "    im_array_pred_combined = np.concatenate(im_array_pred_combined, axis = 0)\n",
    "    im_array_phi_combined = np.concatenate(im_array_phi_combined, axis = 0)\n",
    "    \n",
    "    return im_array_orig_combined, im_array_phi_combined, im_array_pred_combined\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # if (utils.check_gpu(verbose=0)):\n",
    "    if 1:\n",
    "        DATA_MR = 'mr20'\n",
    "        MODEL_FOLDER = 'model_' + DATA_MR\n",
    "        im_study = '../data/original/SRCNN/Test/Set14/monarch.bmp'\n",
    "        # im_study = '../data/original/SRCNN/Test/Set14/baboon.bmp'\n",
    "        \n",
    "        TEST_FOLDER = MODEL_FOLDER + '/tests'\n",
    "        if not(os.path.exists(TEST_FOLDER)):\n",
    "            os.mkdir(TEST_FOLDER)\n",
    "            \n",
    "        url_datafolder = '../data/'\n",
    "        suburl_phi = DATA_MR + '/data_phi.gz'\n",
    "        with open(url_datafolder + suburl_phi, 'rb') as handle:\n",
    "            phi = joblib.load(handle)\n",
    "            print ('1. Phi:', phi, phi.shape)\n",
    "        \n",
    "        model = utils.model_disk('load', MODEL_FOLDER + '/index_network_euclidean_keras_model.json'\n",
    "                               , MODEL_FOLDER + '/index_network_euclidean_keras_weights.h5'\n",
    "                               , ''\n",
    "                       )\n",
    "                                    \n",
    "        im_array_orig_combined, im_array_phi_combined, im_array_pred_combined,  = crop(\n",
    "                                    '../method_euclidean/'\n",
    "                                    , im_study\n",
    "                                    , 33, 33, phi, model\n",
    "                                )\n",
    "        f, axarr = plt.subplots(3,1, figsize= (10,10))\n",
    "        axarr[0].imshow(im_array_orig_combined, cmap = plt.cm.gray)\n",
    "        axarr[1].imshow(im_array_phi_combined, cmap = plt.cm.gray)\n",
    "        axarr[2].imshow(im_array_pred_combined, cmap = plt.cm.gray)\n",
    "        \n",
    "        im_name = im_study.split('/')[-1]\n",
    "        im_dtype = '.' + im_name.split('.')[-1]\n",
    "        im_name = im_name.split('.')[0]\n",
    "        \n",
    "        scipy.misc.imsave(TEST_FOLDER + '/' + im_name + im_dtype              , im_array_orig_combined)\n",
    "        scipy.misc.imsave(TEST_FOLDER + '/' + im_name + '_phi' + im_dtype     , im_array_phi_combined)\n",
    "        scipy.misc.imsave(TEST_FOLDER + '/' + im_name + '_reconnet' + im_dtype, im_array_pred_combined)\n",
    "        \n",
    "    else:\n",
    "        print ('0. Oops! No GPU!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL CHECKS THE PEAK SNR FOR RECONNET IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measured Image 9.47641800698\n",
      "Recovered Image 22.8809742287\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_psnr\n",
    "\n",
    "print ('Measured Image', compare_psnr((im_array_orig_combined).astype('float32')\n",
    "                                           , im_array_phi_combined.astype('float32'), dynamic_range=255))\n",
    "\n",
    "print ('Recovered Image', compare_psnr((im_array_orig_combined).astype('float32')\n",
    "                                           , im_array_pred_combined, dynamic_range=255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL IS FOR EXPERIMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
