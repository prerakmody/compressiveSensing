{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "1. Recreate the model.\n",
    "2. Add the weights\n",
    "3. Split your image into equivalient parts\n",
    "4. Apply phi on them\n",
    "5. Pass them through the NN\n",
    "6. Reconstruct the image via its parts\n",
    "7. Apply BN3D denoiser\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL PREDICTS LOCAL PATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11,
     22,
     45,
     65
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import utils\n",
    "\n",
    "import io\n",
    "import joblib\n",
    "import image_slicer\n",
    "import numpy as np\n",
    "import scipy.ndimage as spimg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "np.random.seed(7)\n",
    "%matplotlib inline\n",
    "\n",
    "def get_data_patches(url_local, file):\n",
    "    obj = spimg.imread(url_local + '/' + file, flatten=True, mode = 'L')\n",
    "    print (obj.shape)\n",
    "    tiles = image_slicer.main.slice(url_local + '/' + file, 4, save=False)\n",
    "    for tile in tiles:\n",
    "        print (tile)\n",
    "        with io.BytesIO() as data:\n",
    "            tile.save(data)\n",
    "            tmp = data.getvalue()\n",
    "            # print (tmp)\n",
    "\n",
    "def get_data_patches_v2(url_datafolder, suburl_phi, suburl_testfolder, suburl_testimage):\n",
    "    objs_original = []\n",
    "    objs_phi = []\n",
    "    \n",
    "    with open(url_datafolder + suburl_phi, 'rb') as handle:\n",
    "        phi = joblib.load(handle)\n",
    "    print ('Phi:', phi, phi.shape)\n",
    "    \n",
    "    obj = spimg.imread(url_datafolder + suburl_testfolder + suburl_testimage, flatten=True, mode = 'L')\n",
    "    plt.imshow(obj, cmap = plt.cm.gray)\n",
    "    print ('Original Image:', obj.shape)\n",
    "    obj_patches = image.extract_patches_2d(obj, (33, 33), max_patches=10)\n",
    "    for obj_patch in obj_patches:\n",
    "        objs_original.append(obj_patch)\n",
    "        obj_patch_flatten = obj_patch.reshape((1, obj_patch.shape[0] * obj_patch.shape[1]))\n",
    "        obj_patch_phi = (obj_patch_flatten * phi).reshape(33,33)\n",
    "        objs_phi.append(obj_patch_phi)\n",
    "        f, axarr = plt.subplots(1,2)\n",
    "        axarr[0].imshow(obj_patch, cmap = plt.cm.gray)\n",
    "        axarr[1].imshow(obj_patch_phi, cmap = plt.cm.gray)\n",
    "    \n",
    "    return objs_original, objs_phi\n",
    "\n",
    "def model_disk(action, filename_model_arch, filename_model_weights, model=''):\n",
    "    from keras.models import model_from_json\n",
    "    \n",
    "    print ('\\n3. --------------------------------------> Model on Disk')\n",
    "    if action == 'save':\n",
    "        with open(filename_model_arch, \"w\") as handle:\n",
    "            handle.write(model.to_json())\n",
    "        model.save_weights(filename_model_weights)\n",
    "        print(\"\\nSaved model to disk\")\n",
    "        \n",
    "    elif action == 'load':\n",
    "        json_file = open(filename_model_arch, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        model.load_weights(filename_model_weights)\n",
    "        print(\"Loaded model from disk\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # get_data_patches('../data/original/SRCNN/Test/Set14/', 'baboon.bmp')\n",
    "    # get_data_patches_v2('../data/','mr_70/data_phi.gz','original/SRCNN/Test/Set14/', 'lenna.bmp')\n",
    "    objs_original, objs_phi = get_data_patches_v2('../data/','mr_70/data_phi.gz'\n",
    "                                                      ,'original/SRCNN/Test/Set14/', 'monarch.bmp')\n",
    "    \n",
    "    model = model_disk('load', 'model/index_network_euclidean_keras_model.json'\n",
    "                               , 'model/index_network_euclidean_keras_weights.h5'\n",
    "                               , ''\n",
    "                       )\n",
    "    for i, obj_phi in enumerate(objs_phi):\n",
    "        obj_predict = model.predict(obj_phi.reshape(1,1,33,33))\n",
    "        print ('obj_predict:', obj_predict.shape)\n",
    "\n",
    "        f, axarr = plt.subplots(1,3)\n",
    "        axarr[0].imshow(obj_phi.reshape(33,33), cmap = plt.cm.gray)\n",
    "        axarr[1].imshow(objs_original[i].reshape(33,33), cmap = plt.cm.gray)\n",
    "        axarr[2].imshow(obj_predict.reshape(33, 33), cmap = plt.cm.gray)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL PREDICTS LOCAL PATCHES AND STITCHES THEM TOGETHER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-06T13:45:06.714Z"
    },
    "code_folding": [
     11,
     35,
     54
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Envs : CUDA_HOME /usr/local/cuda-8.0\n",
      "0. Envs : CUDA_ROOT /usr/local/cuda-8.0\n",
      "0. Envs : LD_LIBRARY_PATH: /usr/local/cuda-8.0/lib64:/usr/lib/nvidia-375\n",
      "0. Envs : PATH (containing cuda) ['/usr/local/cuda-8.0/bin']\n",
      "0. Keras backend: tensorflow\n",
      "0. TensorFlow Devices: name: \"/cpu:0\"device_type: \"CPU\"memory_limit: 268435456locality {}incarnation: 2033225699057768058\n",
      "0. TensorFlow Devices: name: \"/gpu:0\"device_type: \"GPU\"memory_limit: 7143424locality {  bus_id: 1}incarnation: 4398232790065635705physical_device_desc: \"device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0\"\n",
      "\n",
      "\n",
      "1. Phi: [[1 1 0 ..., 0 0 0]] (1, 1089)\n",
      "2. Loaded model from disk\n",
      "3. Original Image: (768, 512) RGB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import utils\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "import joblib\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def check_gpu():\n",
    "    import os\n",
    "    print ('0. Envs : CUDA_HOME', os.environ['CUDA_HOME'])\n",
    "    print ('0. Envs : CUDA_ROOT',os.environ['CUDA_ROOT'])\n",
    "    print ('0. Envs : LD_LIBRARY_PATH:', os.environ['LD_LIBRARY_PATH'])\n",
    "    print ('0. Envs : PATH (containing cuda)', [each for each in os.environ['PATH'].split(':') if each.find('cuda') > -1])\n",
    "    # print ('0. Envs : CUDA_VISIBLE_DEVICES', os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\n",
    "    from keras import backend as K\n",
    "    K.clear_session()\n",
    "    \n",
    "    print ('0. Keras backend:', K.backend())\n",
    "    if K.backend() == 'tensorflow':\n",
    "        from tensorflow.python.client import device_lib\n",
    "        devices = device_lib.list_local_devices()\n",
    "        for device in devices:\n",
    "            print ('0. TensorFlow Devices:', str(device).replace('\\n',''))\n",
    "        print ('\\n')\n",
    "        \n",
    "        return 1 if len(devices) > 1 else 0\n",
    "    \n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def model_disk(action, filename_model_arch, filename_model_weights, model=''):\n",
    "    from keras.models import model_from_json\n",
    "    \n",
    "    if action == 'save':\n",
    "        with open(filename_model_arch, \"w\") as handle:\n",
    "            handle.write(model.to_json())\n",
    "        model.save_weights(filename_model_weights)\n",
    "        print(\"\\nSaved model to disk\")\n",
    "        \n",
    "    elif action == 'load':\n",
    "        json_file = open(filename_model_arch, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        model.load_weights(filename_model_weights)\n",
    "        print(\"2. Loaded model from disk\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def crop(Path, input, height, width, phi, model):\n",
    "    im = Image.open(input)\n",
    "    print ('3. Original Image:', im.size, im.mode)\n",
    "    im = im.convert(\"L\")\n",
    "    \n",
    "    im_numpy = np.array(im)\n",
    "    plt.imshow(im_numpy, cmap = plt.cm.gray)\n",
    "    \n",
    "    im_array_orig = []\n",
    "    im_array_phi = []\n",
    "    im_array_pred = []\n",
    "    \n",
    "    im_array_orig_combined = []\n",
    "    im_array_phi_combined = []\n",
    "    im_array_pred_combined = []\n",
    "    \n",
    "    \n",
    "    imgwidth, imgheight = im.size\n",
    "    total_plots = len(range(0, imgheight, height))\n",
    "    # f, axarr_orig = plt.subplots(total_plots-1,1)\n",
    "    # f, axarr_pred = plt.subplots(total_plots-1,1)\n",
    "    \n",
    "    for row, i in enumerate(range(0, imgheight, height)):\n",
    "        # print ('3. Row:', row, '/', total_plots)\n",
    "        if row > 0:\n",
    "            tmp_img_array_orig = np.array(im_array_orig)\n",
    "            # print ('1. Row:',row-1, ' Image:', tmp_img_array.shape)\n",
    "            tmp_img_array_orig = np.concatenate(tmp_img_array_orig, axis = 1)\n",
    "            # axarr_orig[row-1].imshow(tmp_img_array_orig, cmap = plt.cm.gray)\n",
    "            im_array_orig_combined.append(tmp_img_array_orig)\n",
    "\n",
    "            tmp_img_array_phi = np.array(im_array_phi)\n",
    "            tmp_img_array_phi = np.concatenate(tmp_img_array_phi, axis = 1)\n",
    "            im_array_phi_combined.append(tmp_img_array_phi)\n",
    "\n",
    "            tmp_img_array_pred = np.array(im_array_pred)\n",
    "            tmp_img_array_pred = np.concatenate(tmp_img_array_pred, axis = 1)\n",
    "            # axarr_pred[row-1].imshow(tmp_img_array_pred, cmap = plt.cm.gray)\n",
    "            im_array_pred_combined.append(tmp_img_array_pred)\n",
    "\n",
    "        im_array_orig = []\n",
    "        im_array_phi = []\n",
    "        im_array_pred = []\n",
    "\n",
    "        for j in range(0, imgwidth, width):\n",
    "            box = (j, i, j+width, i+height)  #(x1, y1, x2, y2) (0,0) <-- top-left corner\n",
    "            im_cropped_tmp = np.array(im.crop(box))\n",
    "\n",
    "            im_array_orig.append(im_cropped_tmp)\n",
    "            img_phi_tmp = im_cropped_tmp.reshape(1, width * height) * phi\n",
    "            im_array_phi.append(img_phi_tmp.reshape(width, height))\n",
    "            im_array_pred_tmp = model.predict((img_phi_tmp).reshape(1,1, width, height))\n",
    "            im_array_pred.append(im_array_pred_tmp.reshape(width, height))\n",
    "    \n",
    "    im_array_orig_combined = np.concatenate(im_array_orig_combined, axis = 0)\n",
    "    im_array_pred_combined = np.concatenate(im_array_pred_combined, axis = 0)\n",
    "    im_array_phi_combined = np.concatenate(im_array_phi_combined, axis = 0)\n",
    "    \n",
    "    return im_array_orig_combined, im_array_phi_combined, im_array_pred_combined\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if (utils.check_gpu()):\n",
    "        DATA_MR = 'mr20'\n",
    "        MODEL_FOLDER = 'model_' + DATA_MR\n",
    "        im_study = '../data/original/SRCNN/Test/Set14/monarch.bmp'\n",
    "        # im_study = '../data/original/SRCNN/Test/Set14/baboon.bmp'\n",
    "        \n",
    "        TEST_FOLDER = MODEL_FOLDER + '/tests'\n",
    "        if not(os.path.exists(TEST_FOLDER)):\n",
    "            os.mkdir(TEST_FOLDER)\n",
    "            \n",
    "        url_datafolder = '../data/'\n",
    "        suburl_phi = DATA_MR + '/data_phi.gz'\n",
    "        with open(url_datafolder + suburl_phi, 'rb') as handle:\n",
    "            phi = joblib.load(handle)\n",
    "            print ('1. Phi:', phi, phi.shape)\n",
    "        \n",
    "        model = model_disk('load', MODEL_FOLDER + '/index_network_euclidean_keras_model.json'\n",
    "                               , MODEL_FOLDER + '/index_network_euclidean_keras_weights.h5'\n",
    "                               , ''\n",
    "                       )\n",
    "                                    \n",
    "        im_array_orig_combined, im_array_phi_combined, im_array_pred_combined,  = crop(\n",
    "                                    '../method_euclidean/'\n",
    "                                    , im_study\n",
    "                                    , 33, 33, phi, model\n",
    "                                )\n",
    "        f, axarr = plt.subplots(3,1, figsize= (10,10))\n",
    "        axarr[0].imshow(im_array_orig_combined, cmap = plt.cm.gray)\n",
    "        axarr[1].imshow(im_array_phi_combined, cmap = plt.cm.gray)\n",
    "        axarr[2].imshow(im_array_pred_combined, cmap = plt.cm.gray)\n",
    "        \n",
    "        im_name = im_study.split('/')[-1]\n",
    "        im_dtype = '.' + im_name.split('.')[-1]\n",
    "        im_name = im_name.split('.')[0]\n",
    "        \n",
    "        scipy.misc.imsave(TEST_FOLDER + '/' + im_name + im_dtype              , im_array_orig_combined)\n",
    "        scipy.misc.imsave(TEST_FOLDER + '/' + im_name + '_phi' + im_dtype     , im_array_phi_combined)\n",
    "        scipy.misc.imsave(TEST_FOLDER + '/' + im_name + '_reconnet' + im_dtype, im_array_pred_combined)\n",
    "        \n",
    "    else:\n",
    "        print ('0. Oops! No GPU!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL CHECKS THE PEAK SNR FOR RECONNET IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measured Image 9.47641800698\n",
      "Recovered Image 22.8809742287\n"
     ]
    }
   ],
   "source": [
    "from skimage.measure import compare_psnr\n",
    "\n",
    "print ('Measured Image', compare_psnr((im_array_orig_combined).astype('float32')\n",
    "                                           , im_array_phi_combined.astype('float32'), dynamic_range=255))\n",
    "\n",
    "print ('Recovered Image', compare_psnr((im_array_orig_combined).astype('float32')\n",
    "                                           , im_array_pred_combined, dynamic_range=255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS CELL IS FOR EXPERIMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
