{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "References\n",
    "1. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/\n",
    "\n",
    "\"\"\"\n",
    "print ('Checking all basic libs')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import cv2\n",
    "import joblib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print ('Imported the basic libs ...')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-16T11:40:23.070279Z",
     "start_time": "2017-08-16T11:37:07.382644Z"
    },
    "code_folding": [
     12,
     71
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Total Number of files: 12500\n",
      "0. Batches and their sizes: [3125, 3125, 3125, 3125, 0] \n",
      "\n",
      "\n",
      "0.  ---------------> BATCH NUM: 1  Total Images: 3125\n",
      "0. Sample Filenames: ['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.1000.jpg', 'cat.10000.jpg', 'cat.10001.jpg', 'cat.10002.jpg', 'cat.10003.jpg', 'cat.10004.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 748112 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 40112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 100, 100) \t Memory: 119.20928955078125  MB\n",
      "4. Final Object Array (Single Sample) [[ 96 155 159 ..., 181 181 179]\n",
      " [ 99 157 181 ..., 181 181 179]\n",
      " [112 147 179 ..., 181 181 179]\n",
      " ..., \n",
      " [200 200 200 ..., 138 141 144]\n",
      " [199 199 201 ..., 138 142 145]\n",
      " [199 200 198 ..., 140 141 141]]\n",
      "5. Finished writing file :  data/cats/cats_1.gz\n",
      "5. Total Files Done: 3125 / 12500\n",
      "\n",
      "0.  ---------------> BATCH NUM: 2  Total Images: 3125\n",
      "0. Sample Filenames: ['cat.1560.jpg', 'cat.1561.jpg', 'cat.1562.jpg', 'cat.1563.jpg', 'cat.1564.jpg', 'cat.1565.jpg', 'cat.1566.jpg', 'cat.1567.jpg', 'cat.1568.jpg', 'cat.1569.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 636836 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 40112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 100, 100) \t Memory: 119.20928955078125  MB\n",
      "4. Final Object Array (Single Sample) [[20 18 58 ..., 12 18 18]\n",
      " [22 51 40 ..., 23 21 21]\n",
      " [46  2  9 ..., 22 25 25]\n",
      " ..., \n",
      " [ 3  3  2 ..., 41 39 31]\n",
      " [ 3  3  1 ..., 39 36 28]\n",
      " [ 2  2  4 ..., 35 33 18]]\n",
      "5. Finished writing file :  data/cats/cats_2.gz\n",
      "5. Total Files Done: 6250 / 12500\n",
      "\n",
      "0.  ---------------> BATCH NUM: 3  Total Images: 3125\n",
      "0. Sample Filenames: ['cat.4373.jpg', 'cat.4374.jpg', 'cat.4375.jpg', 'cat.4376.jpg', 'cat.4377.jpg', 'cat.4378.jpg', 'cat.4379.jpg', 'cat.438.jpg', 'cat.4380.jpg', 'cat.4381.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 340656 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 40112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 100, 100) \t Memory: 119.20928955078125  MB\n",
      "4. Final Object Array (Single Sample) [[20 27 13 ..., 17 37 33]\n",
      " [12 24 21 ...,  6 53 54]\n",
      " [20 22 22 ..., 26 12 11]\n",
      " ..., \n",
      " [72 68 77 ..., 19 33 52]\n",
      " [68 75 67 ..., 66 56 59]\n",
      " [66 62 66 ..., 56 56 61]]\n",
      "5. Finished writing file :  data/cats/cats_3.gz\n",
      "5. Total Files Done: 9375 / 12500\n",
      "\n",
      "0.  ---------------> BATCH NUM: 4  Total Images: 3125\n",
      "0. Sample Filenames: ['cat.7186.jpg', 'cat.7187.jpg', 'cat.7188.jpg', 'cat.7189.jpg', 'cat.719.jpg', 'cat.7190.jpg', 'cat.7191.jpg', 'cat.7192.jpg', 'cat.7193.jpg', 'cat.7194.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 298192 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 40112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 100, 100) \t Memory: 119.20928955078125  MB\n",
      "4. Final Object Array (Single Sample) [[ 41  38  37 ...,  29  26  28]\n",
      " [ 33  38  38 ...,  31  25  27]\n",
      " [ 30  31  34 ...,  33  24  26]\n",
      " ..., \n",
      " [ 86 169 164 ..., 161 160 158]\n",
      " [ 63 155 160 ..., 156 160 158]\n",
      " [ 74 118 169 ..., 163 159 157]]\n",
      "5. Finished writing file :  data/cats/cats_4.gz\n",
      "5. Total Files Done: 12500 / 12500\n",
      "\n",
      "0.  ---------------> BATCH NUM: 5  Total Images: 0\n",
      "0. Sample Filenames: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.ndimage as spimg\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# SPLIT DATA INTO BATCHES\n",
    "def get_data(dir_filenames, dir_path, label, filename, file_splits=4, filename_extension='.gz', obj_resize = (300,300)):\n",
    "    labels_all = []\n",
    "    dir_filenames_done = 0\n",
    "    \n",
    "    dir_filenames_blockssize = int(len(dir_filenames)/file_splits)\n",
    "    dir_filenames_lists = [dir_filenames[i*dir_filenames_blockssize : i*dir_filenames_blockssize + dir_filenames_blockssize] for i in range(0, file_splits+1)]\n",
    "    \n",
    "    print ('0. Total Number of files:', len(dir_filenames))\n",
    "    print ('0. Batches and their sizes:', [len(each) for each in dir_filenames_lists], '\\n')\n",
    "    \n",
    "    for j, dir_filenames_list in enumerate(dir_filenames_lists):\n",
    "        print ('\\n0.  ---------------> BATCH NUM:', j+1, ' Total Images:', len(dir_filenames_list))\n",
    "        print ('0. Sample Filenames:', dir_filenames_list[:10])\n",
    "        labels = []\n",
    "        objs = []\n",
    "        if len(dir_filenames_list):\n",
    "            for i, file in enumerate(dir_filenames_list):\n",
    "                if i % 500 == 0:\n",
    "                    print ('1. Reading... ', i, '/', len(dir_filenames_list))\n",
    "                obj = spimg.imread(dir_path + file, flatten=True, mode='L')\n",
    "                objs.append(obj)\n",
    "                labels.append(label)\n",
    "\n",
    "            ## PRINT INFO ON OBJECTS\n",
    "            rand_idx = random.randint(1,len(dir_filenames_list))\n",
    "            print ('2. Total Images :', len(objs))\n",
    "            print ('2. Single Image Size (bytes):', sys.getsizeof(objs[rand_idx]), '\\n')\n",
    "\n",
    "            ## RESIZE ABOVE OBJECTS\n",
    "            tot_objs = len(objs)\n",
    "            for i in range(0,tot_objs):\n",
    "                if i % 500 == 0:\n",
    "                    print ('3. Resizing...', i, '/', tot_objs)\n",
    "                # objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST).flatten()\n",
    "                objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            print ('3. Image Size (resized) (bytes):', sys.getsizeof(objs[rand_idx]))\n",
    "\n",
    "            ## PRINT INFO ON RESIZED OBJECTS\n",
    "            objs_numpy = np.array(objs, dtype=np.int)\n",
    "            print ('4. Final Object Array (ByteSize):', objs_numpy.itemsize)\n",
    "            print ('4. Final Object Array:', objs_numpy.shape, '\\t Memory:', objs_numpy.nbytes/1024.0/1024.0, ' MB')\n",
    "            print ('4. Final Object Array (Single Sample)', objs_numpy[rand_idx])\n",
    "\n",
    "            ## STORE RESIZED OBJECTS\n",
    "            filename_tmp = filename + '_' + str(j+1) + filename_extension\n",
    "            with open(filename_tmp, 'wb') as handle:\n",
    "                # pickle.dump(objs_numpy, handle, protocol=-1)\n",
    "                # np.save(handle, objs_numpy, allow_pickle=True)\n",
    "                joblib.dump(objs_numpy, handle, compress=True)\n",
    "                print ('5. Finished writing file : ', filename_tmp)\n",
    "                labels_all.extend(labels)\n",
    "                dir_filenames_done += len(dir_filenames_list)\n",
    "                print ('5. Total Files Done:', dir_filenames_done, '/', len(dir_filenames))\n",
    "            \n",
    "        \n",
    "    return labels\n",
    "\n",
    "# SAMPLE BATCHES\n",
    "def get_data_sample(dir_filenames, dir_path, label, filename, obj_resize = (300,300), idx_data = 1000):\n",
    "    labels = []\n",
    "    objs = []\n",
    "    for i, file in enumerate(dir_filenames[:idx_data]):\n",
    "        if i % 500 == 0:\n",
    "            print ('1. Reading... ', i, '/', len(dir_filenames))\n",
    "        obj = spimg.imread(dir_path + file, flatten=True, mode='L')\n",
    "        objs.append(obj)\n",
    "        labels.append(label)\n",
    "    \n",
    "    rand_idx = random.randint(1,len(dir_filenames[:idx_data]))\n",
    "    # print ('Total Size (MB)', (np.array(objs).nbytes*1.0)/1024.0/1024.0)\n",
    "    print ('2. Total Images :', len(objs))\n",
    "    print ('2. Single Image Size (bytes):', sys.getsizeof(objs[rand_idx]), '\\n')\n",
    "    \n",
    "    tot_objs = len(objs)\n",
    "    for i in range(0,tot_objs):\n",
    "        if i % 500 == 0:\n",
    "            print ('3. Resizing...', i, '/', tot_objs)\n",
    "        # objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST).flatten()\n",
    "        objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "    \n",
    "    print ('3. Image Size (resized) (bytes):', sys.getsizeof(objs[rand_idx]))\n",
    "    \n",
    "    objs_numpy = np.array(objs, dtype=np.int)\n",
    "    print ('4. Final Object Array (ByteSize):', objs_numpy.itemsize)\n",
    "    print ('4. Final Object Array:', objs_numpy.shape, '\\t Memory:', objs_numpy.nbytes/1024.0/1024.0, ' MB')\n",
    "    print ('4. Final Object Array', objs_numpy[rand_idx])\n",
    "    \n",
    "    with open(filename, 'wb') as handle:\n",
    "        # pickle.dump(objs_numpy, handle, protocol=-1)\n",
    "        # np.save(handle, objs_numpy, allow_pickle=True)\n",
    "        joblib.dump(objs_numpy, handle, compress=True)\n",
    "        \n",
    "    return labels\n",
    "\n",
    "## SAMPLE DATA\n",
    "def view_sample_data(dir_filenames, dir_path, label, filename, obj_resize = (300,300), idx_data = 1000):\n",
    "    f, axarr = plt.subplots(1,2, figsize=(11,11))\n",
    "    rand_idx = random.randint(1,len(dir_filenames))\n",
    "    for i, file in enumerate(dir_filenames):\n",
    "        if i == rand_idx:\n",
    "            print ('Image Name:', file)\n",
    "            obj = spimg.imread(dir_path + file, flatten=True, mode='L')\n",
    "            sample = np.array(obj)\n",
    "            print ('Sample data (Original): ', sample, sample.shape)\n",
    "            axarr[0].imshow(sample, cmap = plt.cm.gray)\n",
    "\n",
    "            obj_resize  = cv2.resize(obj, obj_resize, interpolation=cv2.INTER_NEAREST)\n",
    "            # obj_resize  = cv2.resize(obj, obj_resize, interpolation=cv2.INTER_AREA)\n",
    "            print ('Sample Data (Resized)', obj_resize)\n",
    "            obj_resize_numpy = np.array(obj_resize, dtype=np.int)\n",
    "            print ('Sample Data (resized)', obj_resize_numpy, obj_resize_numpy.shape)\n",
    "            axarr[1].imshow(obj_resize_numpy, cmap = plt.cm.gray)\n",
    "            \n",
    "            print ('-------- BYTES -------')\n",
    "            print ('Original Array (bytes):', sys.getsizeof(obj), ' MB:', sys.getsizeof(obj)/1024.0/1024.0)\n",
    "            print ('Resized Array (bytes):', sys.getsizeof(obj_resize), ' MB:', sys.getsizeof(obj_resize)/1024.0/1024.0)\n",
    "            print ('Resized Array (bytes) (numpy) (sys.getsizeof):', sys.getsizeof(obj_resize_numpy))\n",
    "            print ('Resized Array (bytes) (numpy) (np.nbytes):', obj_resize_numpy.nbytes)\n",
    "\n",
    "            break\n",
    "    \n",
    "\n",
    "## CATS YO!\n",
    "dir_filenames = os.listdir('../data/train/cats/')\n",
    "dir_path = '../data/train/cats/'\n",
    "label = 0\n",
    "dump_filename = 'data/cats/cats'\n",
    "## view_sample_data(dir_filenames, dir_path, label, filename)\n",
    "## labels_cats = get_data_sample(dir_filenames, dir_path, label, filename)\n",
    "labels_cats = get_data(dir_filenames, dir_path, label, dump_filename, file_splits = 4, obj_resize = (100,100))\n",
    "\n",
    "\n",
    "## DOGS YO!\n",
    "# dir_filenames = os.listdir('../data/train/dogs/')\n",
    "# dir_path = '../data/train/dogs/'\n",
    "# label = 0\n",
    "# dump_filename = 'data/dogs/dogs'\n",
    "# view_sample_data(dir_filenames, dir_path, label, dump_filename, obj_resize = (100,100))\n",
    "# labels_dogs = get_data_sample(dir_filenames, dir_path, label, filename)\n",
    "# labels_dogs = get_data(dir_filenames, dir_path, label, dump_filename, file_splits = 4, obj_resize = (100,100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
