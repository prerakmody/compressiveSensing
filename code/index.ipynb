{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "References\n",
    "1. https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import cv2\n",
    "\n",
    "print ('Imported the basic libs ...')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-16T07:25:35.137Z"
    },
    "code_folding": [
     58,
     96
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Total Number of files: 12500\n",
      "0. Batches and their sizes: [3125, 3125, 3125, 3125, 0]\n",
      "0.  ---------------> BATCH NUM: 1  Total Images: 3125\n",
      "0. Sample Filenames: ['dog.0.jpg', 'dog.1.jpg', 'dog.10.jpg', 'dog.100.jpg', 'dog.1000.jpg', 'dog.10000.jpg', 'dog.10001.jpg', 'dog.10002.jpg', 'dog.10003.jpg', 'dog.10004.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 664112 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 360112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 300, 300) \t Memory: 1072.8836059570312  MB\n",
      "4. Final Object Array (Single Sample) [[ 79  70  61 ..., 159 158 158]\n",
      " [ 98  92  87 ..., 160 160 159]\n",
      " [ 98  99 100 ..., 162 161 159]\n",
      " ..., \n",
      " [120 120 120 ..., 113 114 118]\n",
      " [124 122 120 ..., 116 116 117]\n",
      " [122 121 120 ..., 116 116 117]]\n",
      "5. Finished writing file :  cats.z_1.gz \n",
      "\n",
      "5. Total Files Done: 3125 / 12500\n",
      "0.  ---------------> BATCH NUM: 2  Total Images: 3125\n",
      "0. Sample Filenames: ['dog.1560.jpg', 'dog.1561.jpg', 'dog.1562.jpg', 'dog.1563.jpg', 'dog.1564.jpg', 'dog.1565.jpg', 'dog.1566.jpg', 'dog.1567.jpg', 'dog.1568.jpg', 'dog.1569.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 740628 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 360112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 300, 300) \t Memory: 1072.8836059570312  MB\n",
      "4. Final Object Array (Single Sample) [[12 13 16 ...,  6  1  7]\n",
      " [14 14 13 ..., 15  6  6]\n",
      " [ 4  3  2 ..., 26 18  4]\n",
      " ..., \n",
      " [74 79 86 ..., 94 96 93]\n",
      " [78 76 80 ..., 88 91 94]\n",
      " [78 76 80 ..., 88 90 94]]\n",
      "5. Finished writing file :  cats.z_2.gz \n",
      "\n",
      "5. Total Files Done: 6250 / 12500\n",
      "0.  ---------------> BATCH NUM: 3  Total Images: 3125\n",
      "0. Sample Filenames: ['dog.4373.jpg', 'dog.4374.jpg', 'dog.4375.jpg', 'dog.4376.jpg', 'dog.4377.jpg', 'dog.4378.jpg', 'dog.4379.jpg', 'dog.438.jpg', 'dog.4380.jpg', 'dog.4381.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 748612 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 360112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 300, 300) \t Memory: 1072.8836059570312  MB\n",
      "4. Final Object Array (Single Sample) [[102  96 103 ...,  44  28  62]\n",
      " [116 113 110 ...,  52  38  68]\n",
      " [122 121 106 ...,  55  44  66]\n",
      " ..., \n",
      " [ 69  67  75 ...,  81  80  64]\n",
      " [ 58  59  69 ...,  77  72  59]\n",
      " [ 66  58  58 ...,  66  62  72]]\n",
      "5. Finished writing file :  cats.z_3.gz \n",
      "\n",
      "5. Total Files Done: 9375 / 12500\n",
      "0.  ---------------> BATCH NUM: 4  Total Images: 3125\n",
      "0. Sample Filenames: ['dog.7186.jpg', 'dog.7187.jpg', 'dog.7188.jpg', 'dog.7189.jpg', 'dog.719.jpg', 'dog.7190.jpg', 'dog.7191.jpg', 'dog.7192.jpg', 'dog.7193.jpg', 'dog.7194.jpg']\n",
      "1. Reading...  0 / 3125\n",
      "1. Reading...  500 / 3125\n",
      "1. Reading...  1000 / 3125\n",
      "1. Reading...  1500 / 3125\n",
      "1. Reading...  2000 / 3125\n",
      "1. Reading...  2500 / 3125\n",
      "1. Reading...  3000 / 3125\n",
      "2. Total Images : 3125\n",
      "2. Single Image Size (bytes): 344632 \n",
      "\n",
      "3. Resizing... 0 / 3125\n",
      "3. Resizing... 500 / 3125\n",
      "3. Resizing... 1000 / 3125\n",
      "3. Resizing... 1500 / 3125\n",
      "3. Resizing... 2000 / 3125\n",
      "3. Resizing... 2500 / 3125\n",
      "3. Resizing... 3000 / 3125\n",
      "3. Image Size (resized) (bytes): 360112\n",
      "4. Final Object Array (ByteSize): 4\n",
      "4. Final Object Array: (3125, 300, 300) \t Memory: 1072.8836059570312  MB\n",
      "4. Final Object Array (Single Sample) [[254 254 254 ..., 254 254 254]\n",
      " [254 254 254 ..., 254 254 254]\n",
      " [253 251 250 ..., 252 251 252]\n",
      " ..., \n",
      " [251 250 250 ..., 245 245 247]\n",
      " [252 252 250 ..., 251 250 251]\n",
      " [253 253 252 ..., 253 252 252]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import scipy.misc\n",
    "import scipy.ndimage as spimg\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# SPLIT DATA INTO BATCHES\n",
    "def get_data(dir_filenames, dir_path, label, filename, file_splits=4, filename_extension='.gz', obj_resize = (300,300)):\n",
    "    labels_all = []\n",
    "    dir_filenames_done = 0\n",
    "    \n",
    "    dir_filenames_blockssize = int(len(dir_filenames)/file_splits)\n",
    "    dir_filenames_lists = [dir_filenames[i*dir_filenames_blockssize : i*dir_filenames_blockssize + dir_filenames_blockssize] for i in range(0, file_splits+1)]\n",
    "    \n",
    "    print ('0. Total Number of files:', len(dir_filenames))\n",
    "    print ('0. Batches and their sizes:', [len(each) for each in dir_filenames_lists], '\\n')\n",
    "    \n",
    "    for j, dir_filenames_list in enumerate(dir_filenames_lists):\n",
    "        print ('\\n 0.  ---------------> BATCH NUM:', j+1, ' Total Images:', len(dir_filenames_list))\n",
    "        print ('0. Sample Filenames:', dir_filenames_list[:10])\n",
    "        labels = []\n",
    "        objs = []\n",
    "        if len(dir_filenames_lists):\n",
    "            for i, file in enumerate(dir_filenames_list):\n",
    "                if i % 500 == 0:\n",
    "                    print ('1. Reading... ', i, '/', len(dir_filenames_list))\n",
    "                obj = spimg.imread(dir_path + file, flatten=True, mode='L')\n",
    "                objs.append(obj)\n",
    "                labels.append(label)\n",
    "\n",
    "            ## PRINT INFO ON OBJECTS\n",
    "            rand_idx = random.randint(1,len(dir_filenames_list))\n",
    "            print ('2. Total Images :', len(objs))\n",
    "            print ('2. Single Image Size (bytes):', sys.getsizeof(objs[rand_idx]), '\\n')\n",
    "\n",
    "            ## RESIZE ABOVE OBJECTS\n",
    "            tot_objs = len(objs)\n",
    "            for i in range(0,tot_objs):\n",
    "                if i % 500 == 0:\n",
    "                    print ('3. Resizing...', i, '/', tot_objs)\n",
    "                # objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST).flatten()\n",
    "                objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            print ('3. Image Size (resized) (bytes):', sys.getsizeof(objs[rand_idx]))\n",
    "\n",
    "            ## PRINT INFO ON RESIZED OBJECTS\n",
    "            objs_numpy = np.array(objs, dtype=np.int)\n",
    "            print ('4. Final Object Array (ByteSize):', objs_numpy.itemsize)\n",
    "            print ('4. Final Object Array:', objs_numpy.shape, '\\t Memory:', objs_numpy.nbytes/1024.0/1024.0, ' MB')\n",
    "            print ('4. Final Object Array (Single Sample)', objs_numpy[rand_idx])\n",
    "\n",
    "            ## STORE RESIZED OBJECTS\n",
    "            filename_tmp = filename + '_' + str(j+1) + filename_extension\n",
    "            with open(filename_tmp, 'wb') as handle:\n",
    "                # pickle.dump(objs_numpy, handle, protocol=-1)\n",
    "                # np.save(handle, objs_numpy, allow_pickle=True)\n",
    "                joblib.dump(objs_numpy, handle, compress=True)\n",
    "                print ('5. Finished writing file : ', filename_tmp)\n",
    "                labels_all.extend(labels)\n",
    "                dir_filenames_done += len(dir_filenames_list)\n",
    "                print ('5. Total Files Done:', dir_filenames_done, '/', len(dir_filenames))\n",
    "            \n",
    "        \n",
    "    return labels\n",
    "\n",
    "# SAMPLE BATCHES\n",
    "def get_data_sample(dir_filenames, dir_path, label, filename, obj_resize = (300,300), idx_data = 1000):\n",
    "    labels = []\n",
    "    objs = []\n",
    "    for i, file in enumerate(dir_filenames[:idx_data]):\n",
    "        if i % 500 == 0:\n",
    "            print ('1. Reading... ', i, '/', len(dir_filenames))\n",
    "        obj = spimg.imread(dir_path + file, flatten=True, mode='L')\n",
    "        objs.append(obj)\n",
    "        labels.append(label)\n",
    "    \n",
    "    rand_idx = random.randint(1,len(dir_filenames[:idx_data]))\n",
    "    # print ('Total Size (MB)', (np.array(objs).nbytes*1.0)/1024.0/1024.0)\n",
    "    print ('2. Total Images :', len(objs))\n",
    "    print ('2. Single Image Size (bytes):', sys.getsizeof(objs[rand_idx]), '\\n')\n",
    "    \n",
    "    tot_objs = len(objs)\n",
    "    for i in range(0,tot_objs):\n",
    "        if i % 500 == 0:\n",
    "            print ('3. Resizing...', i, '/', tot_objs)\n",
    "        # objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST).flatten()\n",
    "        objs[i] = cv2.resize(objs[i], obj_resize, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "    \n",
    "    print ('3. Image Size (resized) (bytes):', sys.getsizeof(objs[rand_idx]))\n",
    "    \n",
    "    objs_numpy = np.array(objs, dtype=np.int)\n",
    "    print ('4. Final Object Array (ByteSize):', objs_numpy.itemsize)\n",
    "    print ('4. Final Object Array:', objs_numpy.shape, '\\t Memory:', objs_numpy.nbytes/1024.0/1024.0, ' MB')\n",
    "    print ('4. Final Object Array', objs_numpy[rand_idx])\n",
    "    \n",
    "    with open(filename, 'wb') as handle:\n",
    "        # pickle.dump(objs_numpy, handle, protocol=-1)\n",
    "        # np.save(handle, objs_numpy, allow_pickle=True)\n",
    "        joblib.dump(objs_numpy, handle, compress=True)\n",
    "        \n",
    "    return labels\n",
    "\n",
    "## SAMPLE DATA\n",
    "def view_sample_data(dir_filenames, dir_path, label, filename, obj_resize = (300,300), idx_data = 1000):\n",
    "    f, axarr = plt.subplots(1,2, figsize=(11,11))\n",
    "    rand_idx = random.randint(1,len(dir_filenames))\n",
    "    for i, file in enumerate(dir_filenames):\n",
    "        if i == rand_idx:\n",
    "            print ('Image Name:', file)\n",
    "            obj = spimg.imread(dir_path + file, flatten=True, mode='L')\n",
    "            sample = np.array(obj)\n",
    "            print ('Sample data (Original): ', sample, sample.shape)\n",
    "            axarr[0].imshow(sample, cmap = plt.cm.gray)\n",
    "\n",
    "            obj_resize  = cv2.resize(obj, obj_resize, interpolation=cv2.INTER_NEAREST)\n",
    "            print ('Sample Data (Resized)', obj_resize)\n",
    "            obj_resize_numpy = np.array(obj_resize, dtype=np.int)\n",
    "            print ('Sample Data (resized)', obj_resize_numpy, obj_resize_numpy.shape)\n",
    "            axarr[1].imshow(obj_resize_numpy, cmap = plt.cm.gray)\n",
    "            \n",
    "            print ('-------- BYTES -------')\n",
    "            print ('Original Array (bytes):', sys.getsizeof(obj), ' MB:', sys.getsizeof(obj)/1024.0/1024.0)\n",
    "            print ('Resized Array (bytes):', sys.getsizeof(obj_resize), ' MB:', sys.getsizeof(obj_resize)/1024.0/1024.0)\n",
    "            print ('Resized Array (bytes) (numpy) (sys.getsizeof):', sys.getsizeof(obj_resize_numpy))\n",
    "            print ('Resized Array (bytes) (numpy) (np.nbytes):', obj_resize_numpy.nbytes)\n",
    "\n",
    "            break\n",
    "    \n",
    "\n",
    "## CATS YO!\n",
    "# dir_filenames = os.listdir('../data/train/cats/')\n",
    "# dir_path = '../data/train/cats/'\n",
    "# label = 0\n",
    "# dump_filename = 'data/cats/cats'\n",
    "## view_sample_data(dir_filenames, dir_path, label, filename)\n",
    "## labels_cats = get_data_sample(dir_filenames, dir_path, label, filename)\n",
    "# labels_cats = get_data(dir_filenames, dir_path, label, dump_filename, file_splits = 4)\n",
    "\n",
    "\n",
    "## DOGS YO!\n",
    "dir_filenames = os.listdir('../data/train/dogs/')\n",
    "dir_path = '../data/train/dogs/'\n",
    "label = 0\n",
    "dump_filename = 'data/dogs/dogs'\n",
    "# view_sample_data(dir_filenames, dir_path, label, filename)\n",
    "# labels_dogs = get_data_sample(dir_filenames, dir_path, label, filename)\n",
    "labels_dogs = get_data(dir_filenames, dir_path, label, dump_filename, file_splits = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
